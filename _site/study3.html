<!doctype html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">

    <!-- Begin Jekyll SEO tag v2.5.0 -->
<title>Study 3 | Metric-based Fault Prediction for Spreadsheets</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="Study 3" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Study 3 - Importance of feature selection" />
<meta property="og:description" content="Study 3 - Importance of feature selection" />
<link rel="canonical" href="http://localhost:4000/study3.html" />
<meta property="og:url" content="http://localhost:4000/study3.html" />
<meta property="og:site_name" content="Metric-based Fault Prediction for Spreadsheets" />
<script type="application/ld+json">
{"url":"http://localhost:4000/study3.html","headline":"Study 3","description":"Study 3 - Importance of feature selection","@type":"WebPage","@context":"http://schema.org"}</script>
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="/assets/css/style.css?v=6d379d72f7608be83934133fc1f439e86efc672b">
    <title>Study 3</title>
  </head>

  <body>
    <section class="page-header">
      <h1 class="project-name">Metric-based Fault Prediction for Spreadsheets</h1>
      <h2 class="project-tagline">Study 3 - Importance of feature selection</h2>
      <a href="index.html" class="btn">Back to Project Page</a>
    </section>
    <section class="main-content" style="text-align: justify">
      <h1>Description</h1>
  <p>
    In Study 3, we investigate the effect of feature selection on the performance of learnd prediction models for the given classification task.
    In addition to the results shown in the main paper, we also investigated the prediction performance of Random Forest models, when trained only with a set number of the most important features.
    The features were selected on a per-dataset basis. I.e. the features chosen for the Enron Errors dataset are not necessarily the same as chosen for the Info1 dataset.
    The evaluation results were obtained by the same gridsearch-optimized, 10-10 crossvalidation scheme as employed for the main results presented in the paper.
  </p>
<h1>Plot Type</h1>
  <p>
    To compare model prediction performances, we employ a custom plot type, the <b>Precision / Recall / F1 plot</b>, that combines precision, recall, and f1-performance for a specific evaluated model.
    The evaluation result of each trained model is illustrated by a symbol in the plot area.
    For any given symbol in the plot, its horizontal position corresponds to the precision score of the evaluated model.
    Likewise, its vertical precision corresponds to the Recall score of the evaluated model.
    Lastly, the symbol's position in relation to radial lines indicate the model's achieved F1 measure.
  </p>
  <p>
    The first term in the legend refers to the dataset employed for the specific evaluation.
    E.g. ENRON implies that the Random Forest classifier was trained and evaluated on the Enron Errors dataset.
    The bracket information provides insight as to how many of the most important features were used for training and  evaluation.
  </p>
<h1>Plot</h1>
  <p><img src="appendix/plots/limitedFeatures/comparision.png" alt="results of RF classifiers trained using only the 5 most important features" /><a title="(Data CSV))" href="appendix/data/limitedFeatures/comparision.csv">Data CSV</a></p>

    </section>
  </body>
</html>
