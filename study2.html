---
layout: appendix
title: Study 2
description: Study 2 - Fault Prediction with Multiple Metrics
---
<h1>Description</h1>
  <p>
    In Study 2, we evaluate the performance of metric combinations when used to train certain ensemble ML model types to predict faulty spreadsheet cells.
    On this page, we provide additional details about the hyper-parameters obtained by grid-search optimization in form of a table, listing the determined hyper-parameter settings.
    We also provide high-resulution plots that show these results for the different classifier types evaluated on each of the three datasets (Enron Errors, Info1, Euses).
    In addition, we provide boxplots for all datasets that show another perspective on the performances of the individual, learned models during the cross-validation procedure.
  </p>

<h1>Hyper-parameter Settings</h1>
<p>
  We optimized the hyper-parameter values for each algorithm in study 2 for each dataset using grid-search as described in the study setup.
  The resulting best parameter values are listed in the following table.
</p>

<table>
  <caption>Grid search optimized hyper-parameter settings</caption>
  <colgroup>
    <col width="30%" />
    <col width="10%" />
    <col width="20%" />
    <col width="20%" />
    <col width="20%" />
  </colgroup>
  <thead>
    <tr class="header">
      <th align="center">Algorithm</th>
      <th align="center">Parameter</th>
      <th align="center">Enron Errors</th>
      <th align="center">INFO 1</th>
      <th align="center">EUSES</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Random Forest</td>
      <td>N</td>
      <td>50</td>
      <td>5</td>
      <td>50</td>
    </tr>
    <tr>
      <td>SVM (SGD)</td>
      <td>C</td>
      <td>0,001</td>
      <td>0,0001</td>
      <td>0,0001</td>
    </tr>
    <tr>
      <td>AdaBoost</td>
      <td>N</td>
      <td>5</td>
      <td>50</td>
      <td>10</td>
    </tr>
    <tr>
      <td>DNN</td>
      <td>N</td>
      <td>1</td>
      <td>4</td>
      <td>4</td>
    </tr>
  </tbody>
</table>

<h1>Plot Types</h1>
  <p>
    To compare model prediction performances, we employ a custom plot type, the <b>Precision / Recall / F1 plot</b>, that combines precision, recall, and F1-performance for a specific evaluated model.
    The evaluation result of each trained model is illustrated by a symbol in the plot area.
    For any given symbol in the plot, its horizontal position corresponds to the precision score of the evaluated model.
    Likewise, its vertical precision corresponds to the Recall score of the evaluated model.
    Lastly, the symbol's position in relation to radial lines indicate the model's achieved F1 score.
  </p>
  <p>
    The <b>Boxplots</b> provide distribution information of the F1 scores in each individual evaluation during cross-validation.
    For these plots, RF stands for Random Forest, and AB For AdaBoost.
  </p>

<h1>Plots</h1>
  <p>
    Plots are organized into groups based on the employed plot type, first showing <a title="Precision / Recall / F1 plots" href="#predictionPlots">Precision / Recall / F1 plots</a>, and then <a title="Boxplots" href="#boxplots">Boxplots</a> of the evaluation.
  </p>
  <h2 id="predictionPlots">  Precision / Recall / F1 plots </h2>
    <p><img src="appendix/plots/ensemble/ensemble_ENRON.png" alt="ensemble ENRON" /></p>
    <p><img src="appendix/plots/ensemble/ensemble_INFO1.png" alt="ensemble INFO1" /></p>
    <p><img src="appendix/plots/ensemble/ensemble_EUSES.png" alt="ensemble EUSES" /></p>
  <h2 id="boxplots"> Boxplots </h2>
    <p>
      <figcaption>Enron Errors</figcaption>
      <img src="appendix/plots/boxplots/boxplot_ENRON.png" alt="boxplot ENRON" />
    </p>
    <p>
      <figcaption>INFO1</figcaption>
      <img src="appendix/plots/boxplots/boxplot_INFO1.png" alt="boxplot INFO1" />
    </p>
    <p>
      <figcaption>EUSES</figcaption>
      <img src="appendix/plots/boxplots/boxplot_EUSES.png" alt="boxplots EUSES" />
    </p>
