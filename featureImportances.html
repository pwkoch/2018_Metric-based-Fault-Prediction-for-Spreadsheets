---
layout: appendix
title: Feature importances
description: Most important Features of Random Forest Classifiers
---
<h1>Description</h1>
  <p>
    In Study 3, we investigate the effect of feature selection on the performance of learnd prediction models for the given classification task.
    In addition to the results shown in the paper, we also investigated the ranking of feature importances of the different metrics of our catalog based on trained Random Forest classifiers.
    Random Forest models use a number of Decision Trees to infer predictions.
    For this inferrence, each individual trained Decision Tree makes a succession of choices based on the value of individual features (i.e. metrics).
    The more influence a feature has on this decision process (i.e., the more often often it is used to infer a classification), the higher this feature's <b>feature importance</b> score is.
    Trained Random Forest models of the sklearn framework provide a list of quantified feature importance scores for each metric used in our evaluation.
    We determined the most important features for each of the datasets within a 10x10 cross-valdiation scheme, allowing a number of further analysis.
  </p>
  <p>
    First, we determined a number of <a href="#rankings">feature importance rankings</a>, based on different criteria:
    <ul>
      <li><a href="#table1">Table 1</a> shows a top-10 ranking of the most important metrics according to the average feature importance scores per metric across all evaluations.</li>
      <li><a href="#table2">Table 2</a> shows a top-10 ranking of the most important metrics according to a Borda count scheme.</li>
      <li><a href="#table3">Table 3</a> shows a comparison top-10 ranking when applying the same cross-validation scheme as above on a dataset that was created by combining our available datasets (Enron Errors, Info1, Euses) into one.</li>
    </ul>
  </p>
  <p>
    Second, we used <a href="#waterfall">waterfall plots</a> to visualize for each dataset the cumulative feature importance contribution of individual metrics, ranked by each metric's relative contributions.
    <ul>
      <li><a href="#waterfall1">Figure 1</a> shows the results for the Enron Errors dataset.</li>
      <li><a href="#waterfall2">Figure 2</a> shows the results for the INFO1 dataset.</li>
      <li><a href="#waterfall3">Figure 3</a> shows the results for the EUSES dataset.</li>
    </ul>
  </p>
  <p>
    Third, we compared the <a href="#metricUtilities">average metric utilities</a> of metrics of the four different metric categories (cell, formula cell, formula, worksheet) for each dataset.
  </p>
  <p>
    Note that some metrics focus on spreadsheet features that are not used in certain datasets.
    Those metrics consequently do not contribute to any prediction and thus have a feature importance of 0.
    For example, Metric 37, <em>Decision count</em>, counts the number of AND and OR predicates in a formulas.
    The Enron Errors corpus, however, does not make use of those predicates, causing the feature importance of this metric to be 0.
  </p>
  <p>
    Lastly, we investigated the noteworthy performances of worksheet and novel metrics along additional analyses.
    For worksheet metrics, we calculated the <a href="#averageWorksheetMeasures">average measures for worksheet metrics</a> for the cases of (1) all worksheets, (2) faulty worksheets, and (3) correct worksheets of the Enron Errors dataset.
    For novel metrics, we compared the <a href="#novelComparison">performance of Decision Trees</a> traind for individual common (blue) and novel (green) metrics on the various datasets.
  </p>

  <h1 id="discussion">Discussion</h1>
  <p>
    In terms of <b>metric types</b>, we observe that all types of metrics appear in the respective top-10 rankings.
    This finding is also supported by the average metric utility evaluation per category: metrics of all types show to be relevant in all datasets.
    This indicates a pronounced diversity of the prevalent faults, which necessitates a similar diverse set of metrics for successful categorization.
  </p>
    <b>Worksheet metrics</b> are noticeably common within the top-10 lists (3, 6, and 4 entries respectively), and also prove the highest utility ratings per category in all examined datasets.
    In particular, metrics 56, <em>Number of formula cells</em>, 60, <em>Predecessors</em>, and 63, <em>Successors</em>, are part of all three top-10 lists.
    Worksheet metrics, as opposed to the other types, measure properties of the worksheet a given cell is located in.
    The high importance of such metrics reinforces the observation that bigger and more complicated worksheets are more likely to contain faults.
    The comparison of <a href="#averageWorksheetMeasures">average measures for worksheet metrics in Enron Errors</a> supports this conjecutre, where six out of ten metrics depicted significantly higher average readings for worksheets that contain faults.
    Respective measures of worksheet properties thus provide a good first estimate for the likelihood of the individual cells of the worksheet being faulty.
  </p>
  <p>
    <b>Novel metrics</b> were also commonly represented in the top-10 lists (6, 7, and 4 entries respectively).
    This is a noteworthy observation, as only 26 of the 64 measures are considered novel.
    A partial explanation of this finding is that worksheet models performed well, and most of the worksheet models are considered novel contributions.
    However, novel measures that are not worksheet related proved to be important for the prediction task as well.
    <!--In general, we selected novel measures that either (1) cover basic features, (2), use established ideas, or (3) proved to be beneficial in previous research experience.
    Novel metrics are therefore chosen to be distinctive measures of a certain property.-->
    Indeed, comparison of the <a href="#novelComparison">individual prediction performance of common and novel metrics</a> shows that most of our novel contributions outperform many of the common measures in the catalog.
    As combined ML models rely on distinctive measures for accurate predictions, many novel metrics are assessed as more important than their competitors.
  </p>

<h1 id="rankings">Feature importance rankings</h1>
<p>
<table id="table1">
  <caption>Table 1: 10 most important features on average across all datasets</caption>
  <colgroup>
    <col width="10%" />
    <col width="10%" />
    <col width="15%" />
    <col width="35%" />
    <col width="20%" />
    <col width="10%" />
  </colgroup>
  <thead>
    <tr class="header">
      <th align="center">#</th>
      <th align="center">Score</th>
      <th align="center">Metric No</th>
      <th align="center">Name</th>
      <th align="center">Calculated for</th>
      <th align="center">Novel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0,056</td>
      <td>9</td>
      <td>Standard deviation column</td>
      <td>Cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0,053</td>
      <td>56</td>
      <td>Number of formula cells</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0,041</td>
      <td>60</td>
      <td>Predecessors</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0,037</td>
      <td>10</td>
      <td>Standard deviation row</td>
      <td>Cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0,036</td>
      <td>63</td>
      <td>Successors</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0,036</td>
      <td>34</td>
      <td>Similar formulas</td>
      <td>Formula cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0,033</td>
      <td>38</td>
      <td>Length of formula</td>
      <td>Formula</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0,032</td>
      <td>42</td>
      <td>Number of binary operators</td>
      <td>Formula</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0,032</td>
      <td>1</td>
      <td>Column</td>
      <td>Cell</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0,031</td>
      <td>47</td>
      <td>Number of operands</td>
      <td>Formula</td>
      <td>No</td>
    </tr>
  </tbody>
</table>
</p>
<p>
<table id="table2">
  <caption>Table 2: 10 most important features across all datasets using Borda count</caption>
  <colgroup>
    <col width="10%" />
    <col width="10%" />
    <col width="15%" />
    <col width="35%" />
    <col width="20%" />
    <col width="10%" />
  </colgroup>
  <thead>
    <tr class="header">
      <th align="center">#</th>
      <th align="center">Borda</th>
      <th align="center">Metric No</th>
      <th align="center">Name</th>
      <th align="center">Calculated for</th>
      <th align="center">Novel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>169</td>
      <td>56</td>
      <td>Number of formula cells</td>
      <td>worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>2</td>
      <td>165</td>
      <td>1</td>
      <td>Column</td>
      <td>Cell</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>3</td>
      <td>164</td>
      <td>34</td>
      <td>Similar formulas</td>
      <td>Formula cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>4</td>
      <td>164</td>
      <td>63</td>
      <td>Successors</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>5</td>
      <td>162</td>
      <td>60</td>
      <td>Predecessors</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>6</td>
      <td>159</td>
      <td>58</td>
      <td>Unique formulas</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>7</td>
      <td>158</td>
      <td>30</td>
      <td>Column reference spreading</td>
      <td>Formula cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>8</td>
      <td>158</td>
      <td>55</td>
      <td>Cells</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>9</td>
      <td>154</td>
      <td>10</td>
      <td>Standard deviation row</td>
      <td>Cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>10</td>
      <td>152</td>
      <td>57</td>
      <td>Columns</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
</p>
<p>
<table id="table3">
  <caption>Table 3: 10 most important features on the merged dataset</caption>
  <colgroup>
    <col width="10%" />
    <col width="10%" />
    <col width="15%" />
    <col width="35%" />
    <col width="20%" />
    <col width="10%" />
  </colgroup>
  <thead>
    <tr class="header">
      <th align="center">#</th>
      <th align="center">Score</th>
      <th align="center">Metric No</th>
      <th align="center">Name</th>
      <th align="center">Calculated for</th>
      <th align="center">Novel</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0,042</td>
      <td>63</td>
      <td>Successors</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>2</td>
      <td>0,041</td>
      <td>56</td>
      <td>Number of formula cells</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>3</td>
      <td>0,040</td>
      <td>60</td>
      <td>Predecessors</td>
      <td>Worksheet</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>4</td>
      <td>0,040</td>
      <td>9</td>
      <td>Standard deviation column</td>
      <td>Cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>5</td>
      <td>0,037</td>
      <td>40</td>
      <td>Maximal nesting level</td>
      <td>Formula</td>
      <td>No</td>
    </tr>
    <tr>
      <td>6</td>
      <td>0,037</td>
      <td>34</td>
      <td>Similar formulas</td>
      <td>Formula cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>7</td>
      <td>0,036</td>
      <td>64</td>
      <td>Successors in other worksheets</td>
      <td>Worksheet</td>
      <td>No</td>
    </tr>
    <tr>
      <td>8</td>
      <td>0,036</td>
      <td>47</td>
      <td>Number of operands</td>
      <td>Formula</td>
      <td>No</td>
    </tr>
    <tr>
      <td>9</td>
      <td>0,036</td>
      <td>30</td>
      <td>Column reference spreading</td>
      <td>Formula cell</td>
      <td>No</td>
    </tr>
    <tr>
      <td>10</td>
      <td>0,034</td>
      <td>42</td>
      <td>Number of binary operators</td>
      <td>Formula</td>
      <td>Yes</td>
    </tr>
  </tbody>
</table>
</p>

<h1 id="waterfall">Waterfall plots</h1>
<p id="waterfall1"><img src="appendix/plots/featureImportance/waterfall_enron.png" alt="waterfall: cumulative feature importance measures for Enron Errors dataset" /></p>
<p id="waterfall2"><img src="appendix/plots/featureImportance/waterfall_info1.png" alt="waterfall: cumulative feature importance measures for INFO1 dataset" /></p>
<p id="waterfall3"><img src="appendix/plots/featureImportance/waterfall_euses.png" alt="waterfall: cumulative feature importance measures for EUSES dataset" /></p>

<h1 id="metricUtilities">Average metric utilities</h1>
<p><img src="appendix/plots/featureImportance/averageMetricUtility.png" alt="Average metric utility of individual metric types across all datasets" /></p>

<h1 id="averageWorksheetMeasures">Average measures for worksheet metrics</h1>
<p><img src="appendix/plots/featureImportance/averageWorksheetMeasures.png" alt="Average measures of worksheet metrics for Enron Errors dataset" /></p>

<h2 id="novelComparison">Performance of Decision Trees traind for individual common (blue) and novel (green) metrics on the various datasets</h2>
  <p><img src="appendix/plots/featureImportance/novelVsCommon_decisionTree_ENRON.png" alt="Precision-Recall-F1 performance decision trees for common and novel metrics for Enron Errors dataset" /></p>
  <p><img src="appendix/plots/featureImportance/novelVsCommon_decisionTree_INFO1.png" alt="Precision-Recall-F1 performance decision trees for common and novel metrics for Enron INFO1" /></p>
  <p><img src="appendix/plots/featureImportance/novelVsCommon_decisionTree_EUSES.png" alt="Precision-Recall-F1 performance decision trees for common and novel metrics for Enron EUSES" /></p>
